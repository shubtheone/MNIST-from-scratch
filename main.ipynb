{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71319a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab221e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8, 0, 0, ..., 2, 8, 6], shape=(41000,)),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], shape=(784, 41000)))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "m,n # this tells us there are 42000 images each of size 28x28 pixels\n",
    "\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.0 # normalize pixel values (feature scaling) to be between 0 and 1\n",
    "#In the raw MNIST data, each pixel is represented by a number from 0 to 255 \n",
    "# (where 0 is black and 255 is white). We divide by 255 to normalize the data \n",
    "# so that every pixel value falls between 0 and 1.\n",
    "data_dev\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.0 # normalize pixel values (feature scaling) to be between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca83963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(): #initialize parameters for the 2-layer neural network (hidden and output layers)\n",
    "    W1 = np.random.rand(10, 784) - 0.5#hidden layer weights\n",
    "    b1 = np.random.rand(10, 1) - 0.5 #hidden layer bias\n",
    "    W2 = np.random.rand(10, 10) - 0.5#output layer weights\n",
    "    b2 = np.random.rand(10, 1) - 0.5#output layer bias\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0) #activation function ReLU\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z)) #activation function softmax for output layer\n",
    "    #it basically takes output and converts it into probabilities that sum to 1\n",
    "    return A\n",
    "    \n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1  #linear combination for hidden layer, matrix multiplication\n",
    "    A1 = ReLU(Z1)#activation for hidden layer\n",
    "    Z2 = W2.dot(A1) + b2#linear combination for output layer, matrix multiplication\n",
    "    A2 = softmax(Z2)#activation for output layer\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    return Z > 0 #derivative of ReLU activation function to be used in backpropagation Z < 0 always → output = 0 → no gradient\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))# create a matrix of zeros with shape (number of examples, number of classes)\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1# set the appropriate elements to 1 for one-hot encoding\n",
    "    one_hot_Y = one_hot_Y.T# transpose so that each column represents one example\n",
    "    return one_hot_Y# one-hot encoded matrix mainly used for calculating loss and gradients during backpropagation\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)# one-hot encode the true labels\n",
    "    dZ2 = A2 - one_hot_Y # gradient of loss with respect to Z2 (output layer pre-activation) \n",
    "    dW2 = 1 / m * dZ2.dot(A1.T) # gradient of loss with respect to W2 (output layer weights)\n",
    "    db2 = 1 / m * np.sum(dZ2) # gradient of loss with respect to b2 (output layer bias)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)# gradient of loss with respect to Z1 (hidden layer pre-activation)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)# gradient of loss with respect to W1 (hidden layer weights)\n",
    "    db1 = 1 / m * np.sum(dZ1)# gradient of loss with respect to b1 (hidden layer bias)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1   #update weights and biases using gradient descent\n",
    "    b1 = b1 - alpha * db1    #update weights and biases using gradient descent\n",
    "    W2 = W2 - alpha * dW2   #update weights and biases using gradient descent\n",
    "    b2 = b2 - alpha * db2    #update weights and biases using gradient descent\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82cc79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a6d0e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[5 4 1 ... 7 1 5] [8 0 0 ... 2 8 6]\n",
      "0.11131707317073171\n",
      "Iteration:  10\n",
      "[2 9 1 ... 4 8 2] [8 0 0 ... 2 8 6]\n",
      "0.19309756097560976\n",
      "Iteration:  20\n",
      "[2 9 7 ... 4 8 2] [8 0 0 ... 2 8 6]\n",
      "0.2940731707317073\n",
      "Iteration:  30\n",
      "[8 9 7 ... 4 8 8] [8 0 0 ... 2 8 6]\n",
      "0.34014634146341466\n",
      "Iteration:  40\n",
      "[8 9 0 ... 4 8 8] [8 0 0 ... 2 8 6]\n",
      "0.3813170731707317\n",
      "Iteration:  50\n",
      "[8 9 0 ... 4 8 8] [8 0 0 ... 2 8 6]\n",
      "0.42446341463414633\n",
      "Iteration:  60\n",
      "[8 9 0 ... 4 8 8] [8 0 0 ... 2 8 6]\n",
      "0.4621219512195122\n",
      "Iteration:  70\n",
      "[8 0 0 ... 4 8 2] [8 0 0 ... 2 8 6]\n",
      "0.49817073170731707\n",
      "Iteration:  80\n",
      "[8 0 0 ... 6 8 2] [8 0 0 ... 2 8 6]\n",
      "0.530829268292683\n",
      "Iteration:  90\n",
      "[8 0 0 ... 6 8 2] [8 0 0 ... 2 8 6]\n",
      "0.5616585365853659\n",
      "Iteration:  100\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.5901951219512195\n",
      "Iteration:  110\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.6152439024390244\n",
      "Iteration:  120\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.6373658536585366\n",
      "Iteration:  130\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.657829268292683\n",
      "Iteration:  140\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.6749024390243903\n",
      "Iteration:  150\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.6913170731707317\n",
      "Iteration:  160\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7064878048780487\n",
      "Iteration:  170\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7194878048780488\n",
      "Iteration:  180\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7303658536585366\n",
      "Iteration:  190\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7400975609756097\n",
      "Iteration:  200\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7490975609756098\n",
      "Iteration:  210\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7570975609756098\n",
      "Iteration:  220\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7644390243902439\n",
      "Iteration:  230\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7709512195121951\n",
      "Iteration:  240\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7776585365853659\n",
      "Iteration:  250\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7830975609756098\n",
      "Iteration:  260\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7884390243902439\n",
      "Iteration:  270\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7933414634146342\n",
      "Iteration:  280\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.7976585365853659\n",
      "Iteration:  290\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8010731707317074\n",
      "Iteration:  300\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8050975609756098\n",
      "Iteration:  310\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8085365853658537\n",
      "Iteration:  320\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.811609756097561\n",
      "Iteration:  330\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.814560975609756\n",
      "Iteration:  340\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8173170731707317\n",
      "Iteration:  350\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8205853658536585\n",
      "Iteration:  360\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8227317073170731\n",
      "Iteration:  370\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.826\n",
      "Iteration:  380\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8283170731707317\n",
      "Iteration:  390\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8307317073170731\n",
      "Iteration:  400\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8326585365853658\n",
      "Iteration:  410\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8353658536585366\n",
      "Iteration:  420\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8371219512195122\n",
      "Iteration:  430\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8392682926829268\n",
      "Iteration:  440\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8406829268292683\n",
      "Iteration:  450\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8422926829268292\n",
      "Iteration:  460\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8439512195121951\n",
      "Iteration:  470\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8453170731707317\n",
      "Iteration:  480\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.8470243902439024\n",
      "Iteration:  490\n",
      "[8 0 0 ... 6 8 6] [8 0 0 ... 2 8 6]\n",
      "0.848170731707317\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf4cac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4511468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [3]\n",
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test_prediction(45, W1, b1, W2, b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
